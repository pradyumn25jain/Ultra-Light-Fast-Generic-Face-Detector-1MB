{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from functools import partial\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UltraLightFaceDetecion():\n",
    "    def __init__(self, filepath):\n",
    "        # tflite model init\n",
    "        self._interpreter = tf.lite.Interpreter(model_path=filepath)\n",
    "        self._interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "    def _pre_processing(self, img):\n",
    "        # resize image to (240,320,3)\n",
    "        resized = cv2.resize(img,dsize=(320,240))\n",
    "        # bgr to rgb\n",
    "        image_rgb = resized[..., ::-1]\n",
    "        # converting values to float type\n",
    "        image_norm = image_rgb.astype(np.float32)\n",
    "        # normalize all pixel values between -1 and 1 (MinMaX)\n",
    "        cv2.normalize(image_norm, image_norm,\n",
    "                      alpha=-1, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "        # adding another dimension (1, 240, 320, 3)\n",
    "        return image_norm[None, ...]\n",
    "\n",
    "    def inference(self, img):\n",
    "        # BGR image to tensor\n",
    "        input_tensor = self._pre_processing(img)\n",
    "\n",
    "        # get input details, set tensor and invoke\n",
    "        input_details = self._interpreter.get_input_details()\n",
    "        self._interpreter.set_tensor(input_details[0][\"index\"],input_tensor)\n",
    "        self._interpreter.invoke()\n",
    "\n",
    "        # get results (making the inference)\n",
    "        output_details = self._interpreter.get_output_details()\n",
    "        boxes = self._interpreter.get_tensor(output_details[0][\"index\"])[0]\n",
    "        scores = self._interpreter.get_tensor(output_details[1][\"index\"])[0]\n",
    "\n",
    "        # decode boxes to corner format\n",
    "        boxes, scores = self._post_processing(boxes, scores)\n",
    "        # scailing the bounding box according to the aspect ratio\n",
    "        boxes *= np.tile(img.shape[1::-1], 2)\n",
    "        return boxes, scores\n",
    "\n",
    "    def _post_processing(self, boxes, scores):\n",
    "        # bounding box regression\n",
    "        boxes = self._decode_regression(boxes)\n",
    "        # confidencce for every anchor\n",
    "        scores = scores[:, 1]\n",
    "\n",
    "        # confidence threshold filter\n",
    "        conf_mask = 0.6 < scores\n",
    "        # getting all anchors with prob greater then 0.6\n",
    "        boxes, scores = boxes[conf_mask], scores[conf_mask]\n",
    "\n",
    "        # non-maximum suppression\n",
    "        # Prunes away boxes that have high intersection-over-union (IOU) overlap with previously selected boxes\n",
    "        nms_mask = tf.image.non_max_suppression(\n",
    "            boxes, scores, max_output_size=200, iou_threshold=0.3,\n",
    "            score_threshold=float('-inf'), name=None\n",
    "        )\n",
    "        # nms mask contains the indexes of selected boxes\n",
    "        # return boxes that satisfies the requirement \n",
    "        boxes = np.take(boxes, nms_mask, axis=0)\n",
    "        return boxes, scores\n",
    "\n",
    "    def _decode_regression(self, reg):\n",
    "        # bounding box regression\n",
    "        center_variance = 0.1\n",
    "        size_variance = 0.2\n",
    "\n",
    "        # reading the predifened anchors \n",
    "        with open('./anchors_wh.npy', 'rb') as f:\n",
    "            anchors_wh = np.load(f)\n",
    "        with open('./anchors_xy.npy', 'rb') as f:\n",
    "            anchors_xy = np.load(f)\n",
    "\n",
    "        # mathematical operations\n",
    "        center_xy = reg[:, :2] * center_variance * \\\n",
    "            anchors_wh + anchors_xy\n",
    "        center_wh = np.exp(\n",
    "            reg[:, 2:] * size_variance) * anchors_wh / 2\n",
    "\n",
    "        # center to corner for every anchor\n",
    "        start_xy = center_xy - center_wh\n",
    "        end_xy = center_xy + center_wh\n",
    "        # concatenation of box coordinates\n",
    "        boxes = np.concatenate((start_xy, end_xy), axis=-1)\n",
    "        # clip values of boxes between min 0 max 1\n",
    "        boxes = np.clip(boxes, 0.0, 1.0)\n",
    "        return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_inference(img_path, model_path, color=(125, 255, 0)):\n",
    "\n",
    "    fd = UltraLightFaceDetecion(model_path)\n",
    "    # read image\n",
    "    img = cv2.imread(img_path)\n",
    "    # make inference\n",
    "    boxes, scores = fd.inference(img)\n",
    "    # plot the box using the returned coordinates\n",
    "    for result in boxes.astype(int):\n",
    "        cv2.rectangle(img, (result[0], result[1]),\n",
    "                        (result[2], result[3]), color, 2)\n",
    "    # saving the image\n",
    "    cv2.imwrite(os.path.join(\"./data/output/\", img_path.split(\"/\")[-1]), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RFB (higher precision) or slim (faster)\n",
    "mode = 'RFB'\n",
    "img_path = './data/input/2022-01-01_268.png'\n",
    "filepath = f\"pretrained/version-{mode}-320_without_postprocessing.tflite\"\n",
    "image_inference(img_path, filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4af60b990e06954d7df26c4fa0aee1452a440eea4e423a15234bd5ab2623fe07"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('facedetect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
